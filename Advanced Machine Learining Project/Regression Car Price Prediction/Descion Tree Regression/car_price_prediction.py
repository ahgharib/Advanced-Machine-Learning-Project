# -*- coding: utf-8 -*-
"""car-price-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M07RasS6HbF7dgdWbpiYT4BLHQwJfIFW

## **Decision Tree capable of forecasting car prices spanning the years 1970 to 2024.**

# **Imports**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
import joblib
from joblib import dump
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
import random
from sklearn.model_selection import RandomizedSearchCV
from sklearn.tree import DecisionTreeRegressor
from scipy.stats import randint
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

data = pd.read_csv("D:/Advanced Machine Learining Project/Dataset/CarsData2.csv")

"""# **Data Processing**"""

data.shape

data.head(5)

"""**Check for missing data**"""

data.info()

print(data['model'].value_counts())
print('------------------')
print(data['transmission'].value_counts())
print('------------------')
print(data['fuelType'].value_counts())
print('------------------')

"""# **Data Visualization**"""

total_prices_per_year = data.groupby('year')['price'].mean().reset_index()

plt.figure(figsize=(14, 6))
ax = sns.barplot(x='year', y='price', data=total_prices_per_year, palette='rainbow')
ax.set_xticklabels(ax.get_xticklabels())
plt.title('Average Car Price per Year')
plt.show()

data['Manufacturer'].value_counts()

plt.figure(figsize=(14, 6))
ax = sns.countplot(x='Manufacturer', data=data, palette='rainbow')
ax.bar_label(ax.containers[0])
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
plt.title('manufacturer car count')
plt.show()

import plotly.express as px
fuel_type_counts = data["fuelType"].value_counts().reset_index()
fig = px.pie(fuel_type_counts, values='count', names='fuelType', title='Distribution of Fuel Types')
fig.show()

import plotly.express as px
transmission_type_counts = data["transmission"].value_counts().reset_index()
fig = px.pie(transmission_type_counts, values='count', names='transmission', title='Distribution of Transmission Types')
fig.show()

total_prices_per_year = data.groupby('Manufacturer')['price'].mean().reset_index()

plt.figure(figsize=(14, 6))
ax = sns.barplot(x='Manufacturer', y='price', data=total_prices_per_year, palette='rainbow')
ax.set_xticklabels(ax.get_xticklabels())
plt.title('Average Car Price for each Manufacturer')
plt.show()

"""**Looking for correlations**"""

corr_matrix = data.corr(numeric_only=True)
corr_matrix["price"].sort_values(ascending=False)

attributes = ["price", "engineSize", "year","tax", "mpg", "mileage"]
scatter_matrix(data[attributes], figsize=(12, 8))
plt.show()

"""# **Feature scaling**"""

# Data normalization
num_pipeline = Pipeline([
        ("scaler", StandardScaler())
    ])

# Categorical Encoding
cat_pipeline = Pipeline([
        ("cat_encoder", OneHotEncoder()),
    ])

num_attribs = ["engineSize", "year","tax", "mpg", "mileage"]
cat_attribs = ["model", "transmission", "fuelType", "Manufacturer"]
preprocess_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs),
        ("cat", cat_pipeline, cat_attribs),
    ])

X = preprocess_pipeline.fit_transform(data.drop(['price'], axis=1))
joblib.dump(preprocess_pipeline, 'preprocess_pipeline.joblib')
joblib.dump(preprocess_pipeline, 'preprocess_pipeline.pkl')
y = data['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Machine Learning Model: USING DECISION TREE**"""

# train the model
tree_reg = DecisionTreeRegressor(max_depth= 19, min_samples_leaf= 2, min_samples_split= 13)
tree_reg.fit(X_train, y_train)

y_pred_train = tree_reg.predict(X_train)

r2_train = r2_score(y_train, y_pred_train)
print("R-squared on test data:", r2_train)

y_pred_testt = tree_reg.predict(X_test)

r2_test = r2_score(y_test, y_pred_testt )
print("R-squared on test data:", r2_test)

"""**Decision Tree Regression**"""

param_dist = {
    "max_depth": randint(1, 20),
    "min_samples_split": randint(2, 20),
    "min_samples_leaf": randint(1, 20),
}

tree_reg = DecisionTreeRegressor()
random_search = RandomizedSearchCV(tree_reg, param_distributions=param_dist, n_iter=100, cv=5, scoring='r2', random_state=42)
random_search.fit(X_train, y_train)
print("Best parameters:", random_search.best_params_)
best_tree_reg = random_search.best_estimator_
y_pred_test = best_tree_reg.predict(X_test)
r2_test = r2_score(y_test, y_pred_test)
print("R-squared on test data:", r2_test)

model_path = "random_search_dt.joblib"
dump(random_search, model_path)

"""# **Plot the Predicted vs Actual Price**"""

random_indices = random.sample(range(len(y_pred_test)), 15)

plt.figure(figsize=(10, 6))
plt.scatter(random_indices, y_pred_test[random_indices], label='Predicted Price', color='blue', marker='o')
plt.scatter(random_indices, y_test.values[random_indices], label='Actual Price', color='red', marker='s')


for i in random_indices:
    plt.plot([i, i], [y_pred_test[i], y_test.values[i]], color='black', linestyle='-', linewidth=0.5)

plt.title('Actual vs Predicted Prices (Random 15 Prices)')
plt.xlabel('Index')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()